{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Stock Market Prediction And Forecasting Using Stacked LSTM"
      ],
      "metadata": {
        "id": "XAXtPTZu3nHY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "_BNEESG1EJhA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the stock market dataset\n",
        "dataset_url = 'https://raw.githubusercontent.com/mwitiderrick/stockprice/master/NSE-TATAGLOBAL.csv'\n",
        "df = pd.read_csv(dataset_url)"
      ],
      "metadata": {
        "id": "SgtQjWzx52jU"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the dataset\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "df.sort_values(by='Date', inplace=True, ascending=True)\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "dataset = df['Close'].values.reshape(-1, 1)"
      ],
      "metadata": {
        "id": "e7UeETWU52gG"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and testing sets\n",
        "train_data = dataset[:int(0.8 * len(dataset))]\n",
        "test_data = dataset[int(0.8 * len(dataset)):]"
      ],
      "metadata": {
        "id": "cy2RAzCM5_YJ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale the data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "train_data_scaled = scaler.fit_transform(train_data)"
      ],
      "metadata": {
        "id": "QAjyQbXy6BT5"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the training data\n",
        "X_train = []\n",
        "y_train = []\n",
        "for i in range(100, len(train_data_scaled)):\n",
        "    X_train.append(train_data_scaled[i-100:i, 0])\n",
        "    y_train.append(train_data_scaled[i, 0])\n",
        "X_train, y_train = np.array(X_train), np.array(y_train)"
      ],
      "metadata": {
        "id": "H-xryIix6J3P"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape the training data for LSTM\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))"
      ],
      "metadata": {
        "id": "lScdlNn26Jzr"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the Stacked LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
        "model.add(LSTM(units=50, return_sequences=True))\n",
        "model.add(LSTM(units=50))\n",
        "model.add(Dense(units=1))"
      ],
      "metadata": {
        "id": "QM2DyjgV6JpL"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile and train the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdJsJXEp6USZ",
        "outputId": "a27eee5a-fa00-41f9-cc73-69541bb14d54"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "48/48 [==============================] - 9s 99ms/step - loss: 0.0267\n",
            "Epoch 2/10\n",
            "48/48 [==============================] - 5s 112ms/step - loss: 0.0054\n",
            "Epoch 3/10\n",
            "48/48 [==============================] - 5s 98ms/step - loss: 0.0050\n",
            "Epoch 4/10\n",
            "48/48 [==============================] - 5s 104ms/step - loss: 0.0045\n",
            "Epoch 5/10\n",
            "48/48 [==============================] - 5s 111ms/step - loss: 0.0045\n",
            "Epoch 6/10\n",
            "48/48 [==============================] - 5s 100ms/step - loss: 0.0041\n",
            "Epoch 7/10\n",
            "48/48 [==============================] - 5s 112ms/step - loss: 0.0035\n",
            "Epoch 8/10\n",
            "48/48 [==============================] - 5s 100ms/step - loss: 0.0035\n",
            "Epoch 9/10\n",
            "48/48 [==============================] - 5s 112ms/step - loss: 0.0033\n",
            "Epoch 10/10\n",
            "48/48 [==============================] - 5s 99ms/step - loss: 0.0030\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5543217af0>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the test data\n",
        "inputs = df[len(df) - len(test_data) - 100:]['Close'].values\n",
        "inputs = inputs.reshape(-1, 1)\n",
        "inputs = scaler.transform(inputs)\n",
        "X_test = []\n",
        "for i in range(100, len(inputs)):\n",
        "    X_test.append(inputs[i-100:i, 0])\n",
        "X_test = np.array(X_test)\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))"
      ],
      "metadata": {
        "id": "P5GYIwe_6UNU"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict stock prices\n",
        "predicted_stock_prices = model.predict(X_test)\n",
        "predicted_stock_prices = scaler.inverse_transform(predicted_stock_prices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIIqvbBM6UFG",
        "outputId": "eb20165d-f3a7-4a46-eca3-5e3d6f7e6875"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - 1s 26ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "rmse = np.sqrt(np.mean((predicted_stock_prices - test_data)**2))\n",
        "print(\"Root Mean Squared Error (RMSE):\", rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUvP9SM84Bcm",
        "outputId": "fd8ad44f-ade9-40de-a9ae-0720e171e280"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Squared Error (RMSE): 31.19551067952075\n"
          ]
        }
      ]
    }
  ]
}